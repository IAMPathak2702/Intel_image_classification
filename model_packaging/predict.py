import tensorflow as tf
from model_packaging.processing.data_handeling import load_dataset, load_pipeline
from model_packaging.config import config


model = load_pipeline(config.MODEL_NAME)

def evaluate_model(model, test_dataset):
    """
    Evaluate the trained model on the test dataset.

    Args:
        model (tf.keras.Model): Trained model to evaluate.
        test_dataset (tf.data.Dataset): Test dataset.

    Returns:
        Tuple: Evaluation loss and accuracy.
    """
    # Evaluate the model on the test dataset
    loss, accuracy = model.evaluate(test_dataset)
    
    print(f'Test Loss: {loss}')
    print(f'Test Accuracy: {accuracy}')

    return loss, accuracy

# Load the test dataset
test_dataset = load_dataset(config.TEST_FILE, prefetch=True, batch_size=32)  # Assuming you have a function to load your test dataset

# Evaluate the model
evaluate_model(model, test_dataset)

def generate_predictions(model, dataset):
    """
    Generate predictions using the trained model on the given dataset.

    Args:
        model (tf.keras.Model): Trained model for prediction.
        dataset (tf.data.Dataset): Dataset for which predictions are to be generated.

    Returns:
        numpy.ndarray: Predictions generated by the model.
    """
    # Generate predictions using the model
    predictions = model.predict(dataset)
    
    return predictions




if __name__=='__main__':
    generate_predictions()